{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Tips and Tricks\n",
    "\n",
    "\n",
    "### Contents\n",
    "\n",
    "* [Data Preprocessing](#Data-Preprocessing)\n",
    "* [Weight and Bias Initialization](#Weight-and-Bias-Initialization)\n",
    "    * [Xavier-Glorot Initialization](#Xavier-Glorot Initialization)\n",
    "        * [Xavier Normal](#Xavier-Normal)\n",
    "        * [Xavier Uniform](#Xavier-Uniform)\n",
    "    * [Kaiming Normal Initialization](#Kaiming-Normal-Initialization)\n",
    "    * [Orthogonal Initialization](#Orthogonal-Initialization)\n",
    "    * [Initialization Visualization](#Initialization-Visualization)\n",
    "    * [Bias Initialization](#Bias-Initialization)\n",
    "* [Optimizers](#Optimizers)\n",
    "    * [Momentum](#Momentum)\n",
    "    * [Nesterov Momentum](#Nesterov-Momentum)\n",
    "    * [Adagrad](#Adagrad)\n",
    "    * [RMSProp](#RMSProp)\n",
    "    * [Adam](#Adam)\n",
    "* [Unit Tests before you start training](#Unit-Tests-before-you-start-training)\n",
    "    * [Correct Loss value](#Correct-Loss-value)\n",
    "    * [Overfitting test](#Overfitting-test)\n",
    "    * [Gradient Checks](#Gradient-Checks)\n",
    "    * [Inspecting the Learning Rate](#Inspecting-the-Learning-Rate)\n",
    "    * [Learning rate annealing](#Learning-rate-annealing)\n",
    "* [Putting it all together in MXNet](#Putting-it-all-together)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we get started\n",
    "\n",
    "Neural Networks, like other Machine Learning and statistical models, benefit heavily from having data pre-processed to get rid of noisey, inconsistant, and incomplete samples.\n",
    "\n",
    "\n",
    "Please feel free to skip this section if you're familiar with data pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = 15,3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "\n",
    "# Create some fake data\n",
    "xx = np.array([-.5, .5])\n",
    "yy = np.array([-.3, 3])\n",
    "means = [xx.mean(), yy.mean()]  \n",
    "stds = [xx.std() / 3, yy.std() / 3]\n",
    "corr = 0.7        # correlation\n",
    "covs = [[stds[0]**2          , stds[0]*stds[1]*corr], \n",
    "        [stds[0]*stds[1]*corr,           stds[1]**2]] \n",
    "m = np.random.multivariate_normal(means, covs, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few very common techniques are: Zero Centering, Normalizing, PCA, and Whitening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Zero Centering***: subtracting the mean from the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Zero Centered\n",
    "meanx = np.mean(m, axis=0)\n",
    "xx = m - meanx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Normalizing***: standardizing the data so that all dimensions are on the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Normalized\n",
    "stdx = np.std(m, axis = 0)\n",
    "n = xx / stdx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Principal Components Analysis***: removes correlation between variables by reducing the data to a set of *n* uncorrelated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### PCA\n",
    "# get the data covariance matrix of the zero-centered data\n",
    "cov = np.dot(xx.T, xx) / xx.shape[0]\n",
    "# compute the SVD factorization of the data covariance matrix\n",
    "U,S,V = np.linalg.svd(cov)\n",
    "# decorrelate the data\n",
    "Xrot = np.dot(xx, U)\n",
    "# Xrot_reduced becomes [N x 100]\n",
    "Xrot_reduced = np.dot(xx, U[:,:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Whitening***: which reduces correlated variables into a set of *n* uncorrelated variables that all have a variance of 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whiten the data:\n",
    "# divide by the eigenvalues (which are square roots of the singular values)\n",
    "Xwhite = Xrot / np.sqrt(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11947a050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2wAAADSCAYAAAA2REPJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115c2c290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot \n",
    "f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, sharey=True)\n",
    "ax1.plot(m.T[0],m.T[1],'o')\n",
    "ax1.set_title('Original Data')\n",
    "ax2.plot(xx.T[0],xx.T[1],'o')\n",
    "ax2.set_title('Zero Centered Data')\n",
    "ax3.plot(n.T[0],n.T[1],'o')\n",
    "ax3.set_title('Normalized Data')\n",
    "ax4.plot(Xrot_reduced.T[0],Xrot_reduced.T[1],'o')\n",
    "ax4.set_title('PCA - Decorralated Data')\n",
    "ax5.plot(Xwhite.T[0],Xwhite.T[1],'o')\n",
    "ax5.set_title('Whitened Data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight and Bias Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've initilaized $W$ with random initializations. We want the weights to random and as close to zero as possible without actually being zero. This is because if every neuron is zero,  they will compute the same output with the same gradients during backpropagation and undergo the exact same parameter updates. If the weights in a network start too small, then the signal shrinks as it passes through each layer until it’s too tiny to be useful. If the weights in a network start too large, then the signal grows as it passes through each layer until it’s too massive to be useful. So how do we initialize our weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = 10,3\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "np.random.seed(12)\n",
    "\n",
    "def return_weight_data(initializer):\n",
    "    \"\"\"\n",
    "    function to show how the mxnet initializers work\n",
    "    \"\"\"\n",
    "    data = mx.symbol.Variable('data')\n",
    "    weight  = mx.symbol.FullyConnected(data = data, name='weight',\n",
    "                                       num_hidden=500)\n",
    "    mlp = mx.symbol.SoftmaxOutput(data=weight, name='softmax')\n",
    "\n",
    "    # Here we instatiate the model for our data\n",
    "    model = mx.mod.Module(\n",
    "        mlp, context = mx.cpu(0), data_names = ['data'],\n",
    "        label_names = ['softmax_label'],\n",
    "        )\n",
    "    # bind the shapes to the module\n",
    "    model.bind(data_shapes=[['data',(500,500)]], \n",
    "               label_shapes=[['softmax_label',(500,)]])\n",
    "    model.init_params(initializer)\n",
    "    return model.get_params()[0]['weight_weight'].asnumpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavier-Glorot Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Xavier** initialization makes sure the weights are ‘just right’, keeping the signal in a reasonable range of values through many layers; eg the variance on the input and output to be the exact same; thus there are ***Xavier Normal*** and ***Xavier Uniform*** initialization styles, where the normal simply uses Gaussian initializer while the uniform uses a uniform initializer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xavier Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.initializer.Xavier at 0x10fd59710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xavier_normal(shape, gain=1.0):\n",
    "    fan_in, fan_out = shape[0], shape[1]\n",
    "    std = gain * np.sqrt(2.0 / (fan_in + fan_out))\n",
    "    return np.random.uniform(0, std, shape)\n",
    "\n",
    "# xavier_normal mxnet equiv\n",
    "mx.initializer.Xavier(rnd_type='gaussian', \n",
    "                      factor_type='avg', \n",
    "                      magnitude=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xavier Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.initializer.Xavier at 0x119717bd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xavier_uniform(shape, gain=1.0):\n",
    "    fan_in, fan_out = shape[0], shape[1]\n",
    "    std = gain * np.sqrt(2.0 / (fan_in + fan_out))\n",
    "    a = np.sqrt(3.0) * std\n",
    "    return np.random.uniform(-a, a, shape)\n",
    "\n",
    "# xavier_uniform mxnet equiv\n",
    "mx.initializer.Xavier(rnd_type='uniform', \n",
    "                      factor_type='avg', \n",
    "                      magnitude=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaiming Normal Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Kaiming Normal***: Developed for when using ReLUs. A rectifying linear unit is zero for half of its input, so you need to double the size of weight variance to keep the signal’s variance constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.initializer.Xavier at 0x10fd36b10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kaiming_normal(shape, gain=1.0):\n",
    "    fan_in = shape[0]\n",
    "    std = gain * np.sqrt(1.0 / fan_in)\n",
    "    return np.random.uniform(0, std, shape)\n",
    "    \n",
    "# kaiming_normal mxnet equiv\n",
    "mx.initializer.Xavier(rnd_type='uniform', \n",
    "                      factor_type='in', \n",
    "                      magnitude=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Orthogonal***: The eigen values of an Orthogonally initialized matrix are one. Because eigenvalues are what dictate the growth or death of a result as we perform repeated matrix multiplication, this helps in vanishing gradients as they don't explode or diminish. This initialization style is heavily used in RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.initializer.Orthogonal at 0x119717450>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def orthogonal(shape, gain=1.0):\n",
    "    flat_shape = (shape[0], np.prod(shape[1:]))\n",
    "    a = np.random.uniform(0.0, 1.0, flat_shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    # pick the one with the correct shape\n",
    "    q = u if u.shape == flat_shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return gain * q   \n",
    "\n",
    "# orthogonal mxnet equiv\n",
    "mx.initializer.Orthogonal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x127444ad0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAADSCAYAAACfOR4xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6AkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1151ca050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the layers using Numpy instead of Mxnet\n",
    "#tsne = TSNE()\n",
    "#xn = xavier_normal((500,500))\n",
    "#xn = tsne.fit_transform(xn)\n",
    "#xu = xavier_uniform((500,500))\n",
    "#xu = tsne.fit_transform(xu)\n",
    "#kn = kaiming_normal((500,500))\n",
    "#kn = tsne.fit_transform(kn)\n",
    "#o = orthogonal((500,500))\n",
    "#o = tsne.fit_transform(o)\n",
    "\n",
    "# visualize the layers as a scatter plot\n",
    "tsne = TSNE()\n",
    "xn = return_weight_data(mx.initializer.Xavier(rnd_type='gaussian', \n",
    "                      factor_type='avg', \n",
    "                      magnitude=2))\n",
    "xn = tsne.fit_transform(xn)\n",
    "xu = return_weight_data(mx.initializer.Xavier(rnd_type='uniform', \n",
    "                      factor_type='avg', \n",
    "                      magnitude=2))\n",
    "xu = tsne.fit_transform(xu)\n",
    "kn = return_weight_data(mx.initializer.Xavier(rnd_type='uniform', \n",
    "                      factor_type='in', \n",
    "                      magnitude=1))\n",
    "kn = tsne.fit_transform(kn)\n",
    "o = return_weight_data(mx.initializer.Orthogonal())\n",
    "o = tsne.fit_transform(o)\n",
    "\n",
    "#Plot \n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True)\n",
    "ax1.plot(xn[:,0],xn[:,1],'o')\n",
    "ax1.set_title('Xavier Normal')\n",
    "ax2.plot(xu[:,0],xu[:,1],'o')\n",
    "ax2.set_title('Xavier Uniform')\n",
    "ax3.plot(kn[:,0],kn[:,1],'o')\n",
    "ax3.set_title('Kaiming Normal')\n",
    "ax4.plot(o[:,0],o[:,1],'o')\n",
    "ax4.set_title('Orthogonal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Initializing biases***: It is  common to simply use a vector of 0s for the bias initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization TL;DR\n",
    "\n",
    "**TL:DR**: If you're using ReLU activations, you should stick with the kaiming-normal initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going into the details of the various optimizers will be beyond the scope of this workshop; however, it is important to have a general idea of how a select few are different. (for much futher detailed explainations, please see the following list)\n",
    "\n",
    ">[Advances in optimizing Recurrent Networks by Yoshua Bengio, Section 3.5](http://arxiv.org/pdf/1212.0901v2.pdf)\n",
    "\n",
    ">[lya Sutskever’s thesis (pdf) contains a longer exposition of the topic in section 7.2](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)\n",
    "\n",
    ">[Adagrad, Duchi et al.](http://jmlr.org/papers/v12/duchi11a.html)\n",
    "\n",
    ">[slide 29 of Lecture 6 of Geoff Hinton’s Coursera class](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)\n",
    "\n",
    ">[Adam: A Method for Stochastic Optimization](http://arxiv.org/abs/1412.6980)\n",
    "\n",
    ">[Unit Tests for Stochastic Optimization](http://arxiv.org/abs/1312.6055)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Momentum (SGD with a momentum parameter)**: This optimization strategy comes from the physical perspective of the optimization problem where one tries to mimic the process of simulating the parameter vector (i.e. a particle) as rolling on a physical landscape. In this view, setting a particle with zero initial velocity at a given location is the equivalent to initializing parameters with random numbers. We relate the force on the particle to the gradient and the force felt on that particle (acceleration) as the negative gradient of the loss function. Basically, this process will begin to build velocity in any direction that has consistent gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Momentum update\n",
    "v = 0.0 # starts at zero\n",
    "mu = 0.9 #[.5,.9,.99]\n",
    "v = mu * v - learning_rate * dx # integrate velocity\n",
    "x += v # integrate position\n",
    "\n",
    "# mxnet version\n",
    "mxnet.optimizer.SGD(momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nesterov Momentum (NAG - Nesterov Accelerated Gradient)** Differs from regular Momentum in that instead of evaluating the gradient at it's current position, we know that the momentum is going to carry us ahead to a certain position and therefore evaluate the gradient at that position instead (often called the look-ahead position). We know that with Momentum will push the gradient by a given force to a certain location. With Nesterov Momentum we evaluate the gradient at the vicinity of where we know the gradient will go rather than at the current position. In practice, people prefer to use Nesterov Momentum instead of regular Momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nesterov Momentum update\n",
    "v = 0.0 # starts at zero\n",
    "mu = 0.9 #[.5,.9,.99]\n",
    "x_ahead = x + mu * v\n",
    "# evaluate dx_ahead (the gradient at x_ahead instead of at x)\n",
    "v = mu * v - learning_rate * dx_ahead\n",
    "x += v\n",
    "\n",
    "# mxnet version\n",
    "mxnet.optimizer.NAG(momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adagrad**: proposed by [Duchi et al.](http://jmlr.org/papers/v12/duchi11a.html). The thought process here is that the weights that receive high gradients will have their learning rate reduced and weights that receive small or infrequent updates will have their learning rate increased. A downside of this method is that it stops the network from learning due to it's hyper-aggressiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adagrad\n",
    "# Assume the gradient dx and parameter vector x\n",
    "eps = 1e-7\n",
    "cache += dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "\n",
    "# mxnet version\n",
    "mxnet.optimizer.Adagrad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSProp**: RMSProp adjusts Adagrad by using a moving average of squared gradients instead of squared gradients to reduce Adagrad's aggressive nature. In the code section below, please be sure to compare adagrad and rmsprop. Funnily enough, it has never been published, but instead always cited as [slide 29 of Lecture 6 of Geoff Hinton’s Coursera class](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RMSProp\n",
    "eps = 1e-7\n",
    "cache = decay_rate * cache + (1 - decay_rate) * dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "\n",
    "# mxnet version\n",
    "mxnet.optimizer.RMSProp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adam**: Very similar to RMSProp except with a smoothing version of the gradient instead of its raw form. It also uses a bias correction mechanism to compensate for a 'cold-start' that happens before optimizer algorithms fully 'warm-up'. Adam is currently the recommended default algorithm to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adam\n",
    "eps = 1e-8\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "m = 0.0\n",
    "v = 0.0\n",
    "m = beta1*m + (1-beta1)*dx # cold-start correction\n",
    "v = beta2*v + (1-beta2)*(dx**2) # cold-start correction\n",
    "x += - learning_rate * m / (np.sqrt(v) + eps)\n",
    "\n",
    "# mxnet version\n",
    "mxnet.optimizer.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two gifs below, notice the speed of the various optimizers and keep in mind how one would have to augment learning rates to slow or speed up their progression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/opt1.gif'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/opt2.gif'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Tests before you start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "## Set up our mxnet model to showcase the tips and tricks  \n",
    "#############################################################\n",
    "%matplotlib inline\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from mxnet.callback import log_train_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a logger is a critical part of MXNet's interface. This logger allows you to receive callbacks on training information as well as error exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call our logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our network. In our network, the 'input' to our computational graph is a symbolic variable for our data, usually this is simply named 'data' as well; symbolic variables are used such that during each iteration of training, a minibatch of data is assigned to that variable for computation. \n",
    "\n",
    "The ouput variable here is the SoftmaxOutput symbol. Recall from our Foundations chapter, this a multinomial logistic regression. Within MXNet, the Output variables handle the loss function as well, therefore, we won't need to define our own loss-function for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network declaration as symbols.\n",
    "data = mx.symbol.Variable('data')\n",
    "fc1  = mx.symbol.FullyConnected(data = data, name='fc1', num_hidden=512)\n",
    "act1 = mx.symbol.Activation(data = fc1, name='relu1', act_type=\"relu\")\n",
    "fc2  = mx.symbol.FullyConnected(data = act1, name = 'fc2', num_hidden = 512)\n",
    "act2 = mx.symbol.Activation(data = fc2, name='relu2', act_type=\"relu\")\n",
    "fc3  = mx.symbol.FullyConnected(data = act2, name='fc3', num_hidden=10)\n",
    "mlp = mx.symbol.SoftmaxOutput(data=fc3, name='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll fetch the MNIST dataset and perform PCA on the data to reduce our computational load. We'll also add a bit of noise to the data to make the model more robust to overfitting. After this step, we'll split the data into Training and Testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we fetch MNIST dataset, add some noise, \n",
    "# permutate, and assign the examples to be used on our network\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_pca = PCA(n_components=70).fit_transform(mnist.data)\n",
    "noise = np.random.normal(size=mnist_pca.shape)\n",
    "mnist_pca += noise\n",
    "np.random.seed(1234) # set seed for deterministic ordering\n",
    "p = np.random.permutation(mnist_pca.shape[0])\n",
    "X = mnist_pca[p]\n",
    "Y = mnist.target[p]\n",
    "X_show = mnist.data[p]\n",
    "\n",
    "# This is just to normalize the input to a value inside [0,1],\n",
    "# and separate train set and test set\n",
    "X = X.astype(np.float32)/255\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "X_show = X_show[60000:]\n",
    "Y_train = Y[:60000]\n",
    "Y_test = Y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we assign our training and testing data to an MXNet specific iterator. This iterator is part of a [number of data iterator objects](http://mxnet.io/api/python/io.html#data-iterators) that are part of the MXNet libarary. After we assign our data to each iterator, we take a step to overwrite the 'name' of the data so there will be no naming collisions within the MXNet computational graph - NOTE: this step is done for versions <= 0.9.4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set batch size\n",
    "batch_size = 200\n",
    "train_iter = mx.io.NDArrayIter(X_train, Y_train, batch_size=batch_size)\n",
    "test_iter = mx.io.NDArrayIter(X_test, Y_test, batch_size=batch_size)\n",
    "\n",
    "# A quick work around to prevent mxnet complaining the lack of a softmax_label (0.9.4 only)\n",
    "train_iter.label =  mx.io._init_data(Y_train, allow_empty=True, default_name='softmax_label')\n",
    "test_iter.label =  mx.io._init_data(Y_test, allow_empty=True, default_name='softmax_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we make use of the <code>mxnet.metric.EvalMetric</code> class that allows us to record feedback on the network we've defined. Here we're using <code>sklearn</code>'s implementation of <code>log_loss</code> in order to record how well our network is performing at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the cross-entropy loss function for mxnet evaluation callback\n",
    "class LogLoss(mx.metric.EvalMetric):\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "        super(LogLoss, self).__init__('LogLoss')\n",
    "\n",
    "    def update(self, labels, preds):\n",
    "        label_weight = labels[0].asnumpy()\n",
    "        preds = preds[0].asnumpy()\n",
    "        loss = log_loss(label_weight, preds)\n",
    "        self.loss.append(loss)\n",
    "        self.sum_metric += loss\n",
    "        self.num_inst += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Loss value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we'll take in our Unit-testing is to make sure that we're getting the loss we expect when we define our network. With the MNIST dataset and a Softmax Classifier, for example, we expect the untrained loss to be 2.302. This is because we expect a probability output for 0.1 for each class (10 classes) and because Softmax loss is the negative log probability of the correct class, -ln(0.1) = 2.302. So here we'll test a few initialization strategies to ensure we're picking the correct strategy when we finally start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization using Xavier\n",
      "Untrained predictions (should be close to .1)\n",
      "[0.10522023, 0.10625023, 0.10988785, 0.089549445, 0.091543011, 0.08146327, 0.077686548, 0.091829546, 0.15389612, 0.092673771]\n",
      "Mean prediction 0.10000000149, prediction std 0.0244382936507\n",
      "Total Data Loss: 2.32725609273\n",
      "\n",
      "\n",
      "Initialization using Kaiming Normal\n",
      "Untrained predictions (should be close to .1)\n",
      "[0.10743047, 0.096293211, 0.10858989, 0.093776748, 0.098764867, 0.10363301, 0.093996167, 0.090252951, 0.10381297, 0.10344975]\n",
      "Mean prediction 0.100000008941, prediction std 0.00731063494459\n",
      "Total Data Loss: 2.29337943423\n",
      "\n",
      "\n",
      "Initialization using Orthogonal - 0.25\n",
      "Untrained predictions (should be close to .1)\n",
      "[0.10006409, 0.10023994, 0.099764697, 0.099924028, 0.10011359, 0.099741556, 0.1001128, 0.099977002, 0.099773407, 0.10028884]\n",
      "Mean prediction 0.099999986589, prediction std 0.000210285143112\n",
      "Total Data Loss: 2.30286796756\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_init_strategy(strategy, text):\n",
    "    # Here we instatiate the model for our data\n",
    "    model = mx.mod.Module(\n",
    "        mlp,                             # Use the network we just defined\n",
    "        context = mx.cpu(0),             # Run on CPU 0\n",
    "        data_names = ['data'],           # Provide the name of 'data'\n",
    "        label_names = ['softmax_label'], # Provide the name of 'label\n",
    "        )\n",
    "    # bind the correct shapes\n",
    "    model.bind(data_shapes=train_iter.provide_data,\n",
    "               label_shapes=train_iter.provide_label)\n",
    "\n",
    "    # manually init the params\n",
    "    model.init_params(strategy)\n",
    "\n",
    "    # output the entire test dataset\n",
    "    output = model.predict(test_iter).asnumpy()\n",
    "    \n",
    "    print(\"Initialization using {}\".format(text))\n",
    "    \n",
    "    print(\"Untrained predictions (should be close to .1)\")\n",
    "    print(list(output[0]))\n",
    "    \n",
    "    print(\"Mean prediction {}, prediction std {}\".format(np.mean(output),np.std(output)))\n",
    "    \n",
    "    data_loss = log_loss(Y_test, output)\n",
    "    print(\"Total Data Loss: {}\".format(data_loss))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "test_init_strategy(mx.initializer.Xavier(), 'Xavier')\n",
    "\n",
    "test_init_strategy(mx.initializer.Xavier(rnd_type='uniform', factor_type='in', magnitude=1), 'Kaiming Normal')\n",
    "    \n",
    "test_init_strategy(mx.initializer.Orthogonal(0.25), 'Orthogonal - 0.25')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training on thefull dataset, we'll try to train on a tiny portion of our data (setting regularization to zero again) and make sure we can achieve zero cost. Before, however, we want to make sure our sample data is error and bug free, otherwise we'll pass this test and not be able to generalize to the larger dataset.  \n",
    "\n",
    "One should peform the overfitting test prior to each new dataset being tested. Unless we can accomplish zero cost, we don't want to waste our time training a model for weeks only to find out it can't fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "## This will take a long time ----- so please don't run   ##\n",
    "#############################################################\n",
    "\n",
    "def perform_overfitting_test(mlp, X_train, Y_train, batch_size=50):\n",
    "    # create new dataset from last 100 examples\n",
    "    overfit_train_iter = mx.io.NDArrayIter(X_train[-100:], Y_train[-100:], batch_size=batch_size)\n",
    "    # A quick work around to prevent mxnet complaining the lack of a softmax_label\n",
    "    overfit_train_iter.label =  mx.io._init_data(Y_train[-100:], allow_empty=True, default_name='softmax_label')\n",
    "\n",
    "    # Here we instatiate the model for our data\n",
    "    model = mx.mod.Module(\n",
    "        mlp,                             # Use the network we just defined\n",
    "        context = mx.cpu(0),             # Run on CPU 0\n",
    "        data_names = ['data'],           # Provide the name of 'data'\n",
    "        label_names = ['softmax_label'], # Provide the name of 'label\n",
    "        )\n",
    "    # bind the shapes to the module\n",
    "    model.bind(data_shapes=overfit_train_iter.provide_data,\n",
    "               label_shapes=overfit_train_iter.provide_label)\n",
    "\n",
    "    # call fit to make sure you can achieve 0 loss\n",
    "    model.fit(\n",
    "        train_data = overfit_train_iter,\n",
    "        num_epoch = 5000,\n",
    "        eval_metric = LogLoss(),\n",
    "        initializer = mx.init.Orthogonal(0.25),\n",
    "        optimizer_params = {'learning_rate':0.1, 'momentum': 0.9, 'wd':0.00001},\n",
    "        batch_end_callback = log_train_metric(500),\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It's also very important to peform gradient checks on the model you've built. A gradient check is where one compares the analytic gradient to the numeric gradient. Under the hood, many things are taken care of, but it's important to know why these things are happening:\n",
    "\n",
    "Gradient checking involes using the **centered difference formula** to evaluate the numeric gradient\n",
    "\n",
    "   $$\\frac{df(x)}{dx} = \\frac{f(x + h) - f(x - h)}{2h} \\hspace{0.1in}$$\n",
    "\n",
    "and the **relative error** between the numeric and analytic gradients\n",
    "\n",
    "$$\\frac{\\mid f'_a - f'_n \\mid}{\\max(\\mid f'_a \\mid, \\mid f'_n \\mid)}$$\n",
    "\n",
    "which considers their ratio of the differences to the ratio of the absolute values of both gradients. In practice:\n",
    "\n",
    "* relative error > 1e-2 usually means the gradient is probably wrong\n",
    "* 1e-2 > relative error > 1e-4 should make you feel uncomfortable\n",
    "* 1e-4 > relative error is usually okay for objectives with kinks. But if there are no kinks (e.g. use of tanh nonlinearities and softmax), then 1e-4 is too high.\n",
    "* 1e-7 and less you should be happy.\n",
    "\n",
    "The deeper the network, the higher the relative errors will be. For example, a single differentiable function with an error of 1e-2 indicates an incorrect gradient, however, for a deep 100 layer network, a relative error of around 1e-2 might be okay because the errors build up on the way. \n",
    "\n",
    "Important points to consider when performing Gradient Checks:\n",
    "\n",
    "**Use double precision.** Thankfully, MXNet takes care of this for you, but a common mistake in the past that many scientists make is using single precision floating point to compute gradient check. Often, you will get high relative errors, even with a correct gradient implementation.\n",
    "\n",
    "**Always print the raw numerical/analytic gradient,** and make sure that the numbers you are comparing are not extremely small. Andre Karpathy recommends scaling your loss function by some constant to bring them into what he calls a 'nicer' range where floats are 'more dense' - ideally on the order of 1.0, where your float exponent is 0.\n",
    "\n",
    "**Beware of non-differentiable parts of an objective function**, introduced by functions such as ReLU (max(0,x). Consider the case of the ReLU (x < 0) if x-=1e6: the analytic gradient is exactly zero. However, the numeric gradient might compute a non-zero gradient if the area during numeric computation crosses over the non-differentiable portion of the function; $f(x+h)$ if $h > 1e-6$.\n",
    "\n",
    "**Using a few datapoints.**: Using very few datapoints makes your gradient check faster and more efficient.\n",
    "\n",
    "**Burn in period**. It is best to use a short burn-in period after the network has been allowed to learn and the loss starts to go down. If the gradient check is performed at first iteration, it could mask an incorrect implementation of the gradient.\n",
    "\n",
    "**Turn off Regularization if you're using it**: a loss function is a sum of the data loss and the regularization loss (e.g. L2 penalty on weights). Sometimes the regularization loss may overwhelm the data loss, in which case the gradients will be primarily coming from the regularization term. This can mask an incorrect implementation of the data loss gradient. Also be sure to turn off dropout/data augmentations.\n",
    "\n",
    "Lastly, **Make sure to gradient check a few dimensions for every separate parameter**\n",
    "\n",
    "\n",
    "# ***Thankfully, MXNet (as well as other modern DL libraries) has the above built-in to make gradient checking a lot easier on the user.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################################\n",
    "## This will kill the jupyter kernel -- so please don't run #\n",
    "#############################################################\n",
    "\n",
    "from mxnet.test_utils import check_numeric_gradient\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def perform_gradient_test(mlp, X_train, Y_train):\n",
    "    # create new dataset from last 10 examples\n",
    "    overfit_train_iter = mx.io.NDArrayIter(X_train[-10:], \n",
    "                                           Y_train[-10:], \n",
    "                                           batch_size=10)\n",
    "    \n",
    "    # A quick work around to prevent mxnet complaining the lack of a softmax_label\n",
    "    overfit_train_iter.label =  mx.io._init_data(Y_train[-10:], \n",
    "                                    allow_empty=True, \n",
    "                                    default_name='softmax_label')\n",
    "\n",
    "    # Here we instatiate the model for our data\n",
    "    model = mx.mod.Module(\n",
    "        mlp,                             # Use the network we just defined\n",
    "        context = mx.cpu(0),             # Run on CPU 0\n",
    "        data_names = ['data'],           # Provide the name of 'data'\n",
    "        label_names = ['softmax_label'], # Provide the name of 'label\n",
    "        )\n",
    "    # bind the shapes to the module\n",
    "    model.bind(data_shapes=overfit_train_iter.provide_data,\n",
    "               label_shapes=overfit_train_iter.provide_label)\n",
    "    \n",
    "    # call fit to burn-in the model\n",
    "    model.fit(\n",
    "        train_data = overfit_train_iter,\n",
    "        num_epoch = 500,\n",
    "        eval_metric = LogLoss(),\n",
    "        initializer = mx.initializer.Xavier(),\n",
    "        optimizer_params = {'learning_rate':0.1, 'momentum': 0.9, 'wd':0.00001},\n",
    "        batch_end_callback = log_train_metric(500),\n",
    "    )\n",
    "    \n",
    "    # copy the model's parameters and inject the variables for \n",
    "    # 'data' and 'softmax_label'\n",
    "    parameters = deepcopy(model.get_params()[0])\n",
    "    parameters['data'] = overfit_train_iter.getdata()[0]\n",
    "    parameters['softmax_label'] = overfit_train_iter.getlabel()[0]\n",
    "\n",
    "    # perform gradient check\n",
    "    check_numeric_gradient(mlp, parameters)\n",
    "\n",
    "\n",
    "# you should see something similar to this below if there is something wrong\n",
    "\n",
    "\"\"\"\n",
    "---------------------------------------------------------------------------\n",
    "AssertionError                            Traceback (most recent call last)\n",
    "<ipython-input-191-150091434937> in <module>()\n",
    "----> 1 check_numeric_gradient(mlp,parameters)\n",
    "\n",
    "/Users/krzum/anaconda3/envs/ml/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/test_utils.pyc in check_numeric_gradient(sym, location, aux_states, numeric_eps, rtol, atol, grad_nodes, use_forward_train, ctx)\n",
    "    518         if grad_req[name] == 'write':\n",
    "    519             assert_almost_equal(fd_grad, sym_grad, rtol, atol,\n",
    "--> 520                                 (\"NUMERICAL_%s\"%name, \"BACKWARD_%s\"%name))\n",
    "    521         elif grad_req[name] == 'add':\n",
    "    522             assert_almost_equal(fd_grad, sym_grad - orig_grad, rtol, atol,\n",
    "\n",
    "/Users/krzum/anaconda3/envs/ml/lib/python2.7/site-packages/mxnet-0.9.5-py2.7.egg/mxnet/test_utils.pyc in assert_almost_equal(a, b, rtol, atol, names)\n",
    "    149                             % (rel, rtol, atol, str(index), a[index], b[index]),\n",
    "    150                             names=names)\n",
    "--> 151     raise AssertionError(msg)\n",
    "    152 \n",
    "    153 \n",
    "\n",
    "AssertionError: \n",
    "Items are not equal:\n",
    "Error 1521893.750000 exceeds tolerance rtol=0.010000, atol=0.000000.  Location of maximum error:(110, 56), a=0.000121, b=-0.000000\n",
    " NUMERICAL_data: array([[ 0.00000001, -0.        , -0.00000001, ...,  0.        ,\n",
    "        -0.        ,  0.00000001],\n",
    "       [ 0.00000446, -0.00000987,  0.00000123, ...,  0.00000095,...\n",
    " BACKWARD_data: array([[-0.        , -0.00000001, -0.        , ..., -0.        ,\n",
    "         0.        ,  0.        ],\n",
    "       [ 0.00000526, -0.0000118 ,  0.00000154, ...,  0.00000116,...\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've performed the above steps, the next step is to inspect our loss function to ensure our optimizer and loss function parameters are chosen correctly. It's important to plot the slope of the loss function to ensure the network is learning properly. The below image is a general heuristic we use to evaluate that our initial learning rate is being chosen properly. \n",
    "\n",
    "<img src='files/learningrates.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "INFO:root:Iter[0] Batch[0] Train-LogLoss=2.302891\n",
      "INFO:root:Epoch[0] Train-LogLoss=0.535295\n",
      "INFO:root:Epoch[0] Time cost=1.937\n",
      "INFO:root:Epoch[0] Validation-LogLoss=0.130427\n",
      "INFO:root:Iter[1] Batch[0] Train-LogLoss=0.159358\n",
      "INFO:root:Epoch[1] Train-LogLoss=0.103304\n",
      "INFO:root:Epoch[1] Time cost=1.901\n",
      "INFO:root:Epoch[1] Validation-LogLoss=0.087567\n",
      "INFO:root:Iter[2] Batch[0] Train-LogLoss=0.112749\n",
      "INFO:root:Epoch[2] Train-LogLoss=0.069140\n",
      "INFO:root:Epoch[2] Time cost=2.147\n",
      "INFO:root:Epoch[2] Validation-LogLoss=0.074296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11a0afe90>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XeYVNXBx/HvmbK7tAWkLEhHUaQJShApBhEsoJJiLIlJ\nNFETW2JeXxMssSdojL7WxBijBmuixgqoiCKCSqT3skjbZWGXtpXt5/1jCjO7s32WYe/9fZ5nH2bu\n3Jk5Z9n53TPnnnOusdYiIiLO4kl0AUREJP4U7iIiDqRwFxFxIIW7iIgDKdxFRBxI4S4i4kAKdxER\nB1K4i4g4kMJdRMSBfIl6486dO9u+ffsm6u1FRFqkpUuX7rXWdqlrv4SFe9++fVmyZEmi3l5EpEUy\nxmyvz37qlhERcSCFu4iIAyncRUQcSOEuIuJACncREQdSuIuIOJDCXUTEgRI2zr2x0rPzeXdlFl3a\nJtGnUxtO7tWB9q38iS6WiMhRpcWF+/qsfJ74ZDOhS7+2SfJyWv9OfHdEDy44+djEFk5E5ChhEnWB\n7JEjR9rGzlAtq6jkm5xCtu4t5P5Z68g4cAiA747owSMXn4wxJp5FFRE5ahhjllprR9a1X4vsc/d7\nPZzYrR3nDunG/P+dwC3nnAjAW8szeW9VVoJLJyKSeC0y3CP5vB6uP/N47rlwMAAfrtmd4BKJiCRe\niw/3kJ+O6cvEgV2ZtTqLtbtyE10cEZGEcky4A5zapyMAD36wMcElERFJLEeF+1Xj+wFQVl6Z4JKI\niCSWo8I92eflx6P7sDozl/IKBbyIuJejwh1g7PGdKCgpZ+n2A4kuiohIwjgu3AektQMgK7c4wSUR\nEUkcx4X7Ma2TADhQVJrgkoiIJI7jwj21lR9j4EChwl1E3Mtx4e71GI5pnUROQUmiiyIikjCOC3eA\n47q2ZdOegkQXQ0QkYRwZ7gO7tWPj7nwqKxOzKJqISKI5NNxTKSgpJ/PgoUQXRUQkIRwZ7j06tgIg\nO1/DIUXEnRwZ7p3aBIZD7i3QiBkRcSdHhnvntskA7NWIGRFxKYeGexIdWvtZlL430UUREUkIR4a7\nz+thYLd27M1Xt4yIuJMjwx0Cl+Ir1cqQIuJSjg33JK+H8kqFu4i4U53hbozpZYz51Bizzhiz1hjz\n6xj7GGPM48aYdGPMKmPMKc1T3Przez2UlWsSk4i4k68e+5QDN1trlxlj2gFLjTFzrbXrIvY5DxgQ\n/DkN+Gvw34TxeQ1l6pYREZeqs+Vurc2y1i4L3s4H1gM9quw2DZhpA74COhhjuse9tA2Q5PVQpm4Z\nEXGpBvW5G2P6AiOAxVUe6gHsjLifQfUDAMaYa4wxS4wxS3JychpW0gZSt4yIuFm9w90Y0xZ4E7jJ\nWpvXmDez1j5jrR1prR3ZpUuXxrxEvfm8RidURcS16hXuxhg/gWB/2Vr7nxi7ZAK9Iu73DG5LGL/X\nw96CUl0oW0RcqT6jZQzwD2C9tfaRGnZ7F/hJcNTMaCDXWpsVx3I22Fff7APg6c+2JLIYIiIJUZ/R\nMmOBHwOrjTErgttuA3oDWGufBmYDU4B0oAi4Mv5FbZjQcr+7dKFsEXGhOsPdWrsQMHXsY4Hr41Wo\neAgNg2zt9ya4JCIiR55jZ6h6TeB4lOx3bBVFRGrk2OR76arAHKq2yf4El0RE5MhzbLif3LMDACXl\nFQkuiYjIkefYcPd4DEleDyXlGgopIu7j2HAHSPZ5KC5Ty11E3MfZ4e73quUuIq7k7HBXy11EXMrR\n4Z7iV5+7iLiTo8M92eelRC13EXEhR4e7Wu4i4laODvdkn1d97iLiSo4Od7XcRcStHB3uarmLiFs5\nOtzVchcRt3J0uCf7vBwqVctdRNzH0eHesU0SB4pKCSw3LyLiHo4O97TUZMoqLAeKyhJdFBGRI8rR\n4d61XQoA2fm61J6IuIujwz0tNRmAPXklCS6JiMiR5ehwD7Xc9+Sp5S4i7uLocO/SLtByz8lXy11E\n3MXR4Z4SvDh2qca6i4jLODrcjTF4PYbySoW7iLiLo8MdCIa7xrmLiLs4Ptz9HkN5hcJdRNzF8eHu\n9Rgq1HIXEZdxfLj7vR7KKtTnLiLu4vhwV8tdRNzI8eEeaLkr3EXEXRwf7oGWu7plRMRdHB/uPq+h\nTN0yIuIyzg93j6FC3TIi4jKOD3evx6MZqiLiOo4Pd79XM1RFxH3qDHdjzHPGmGxjzJoaHp9gjMk1\nxqwI/twZ/2I2nlczVEXEhXz12OcF4ElgZi37fG6tPT8uJYozv7plRMSF6my5W2sXAPuPQFmahVru\nIuJG8epzH2OMWWWMmWOMGVzTTsaYa4wxS4wxS3JycuL01rXr0bEVG/fkawkCEXGVeIT7MqC3tXYY\n8ATwdk07WmufsdaOtNaO7NKlSxzeum5Djk0lv7icguLyI/J+IiJHgyaHu7U2z1pbELw9G/AbYzo3\nuWRx4vMGqqiWu4i4SZPD3RjTzRhjgrdHBV9zX1NfN16SQuGu4ZAi4iJ1jpYxxrwKTAA6G2MygLsA\nP4C19mngIuBaY0w5cAi41Fp71CSp32cAKNN1VEXEReoMd2vtZXU8/iSBoZJHJZ9H3TIi4j4umKEa\nCvej5suEiEizc3y4J4W6ZdRyFxEXcXy4h7plNEtVRNzE8eEe6pYpLVe3jIi4hwvCXd0yIuI+Lgh3\ndcuIiPu4JtzVLSMibuKCcFe3jIi4jwvCXd0yIuI+jg93X6jlrm4ZEXERx4f74YXD1HIXEfdwfLiH\nlx/QwmEi4iKOD/dQt8zsNbsTXBIRkSPH8eEearn/d2uLvQysiEiDuSbcQcMhRcQ9HB/uXo8J39Z1\nVEXELRwf7pHyissSXQQRkSPCXeF+SC13EXEHV4X7obKKRBdBROSIcFW464SqiLiFq8K9VOEuIi7h\nqnDXLFURcQtXhPv7N44D1HIXEfdwRbi3TfYB6nMXEfdwRbj7faHFw7Tsr4i4gzvCPbh4mLplRMQt\nXBHuyV4voG4ZEXEPV4S73xdsuWu0jIi4hDvCPXTBDrXcRcQlXBHuPk+oz10nVEXEHVwR7sYYkrwe\ntdxFxDVcEe4AST6P+txFxDVcE+5+r1HLXURcw0Xhrm4ZEXGPOsPdGPOcMSbbGLOmhseNMeZxY0y6\nMWaVMeaU+Bez6fxeD6WaoSoiLlGflvsLwLm1PH4eMCD4cw3w16YXK/6SfB7NUBUR16gz3K21C4D9\ntewyDZhpA74COhhjusergPGS5PVoyV8RcY149Ln3AHZG3M8IbqvGGHONMWaJMWZJTk5OHN66/vw+\nnVAVEfc4oidUrbXPWGtHWmtHdunS5Ui+daDPXeEuIi4Rj3DPBHpF3O8Z3HZUCZxQVbiLiDvEI9zf\nBX4SHDUzGsi11mbF4XXjSjNURcRNfHXtYIx5FZgAdDbGZAB3AX4Aa+3TwGxgCpAOFAFXNldhmyLF\n72Fh+kFyD5XRvpU/0cUREWlWdYa7tfayOh63wPVxK1EzmXBiVz5en83ib/Zx9uBuiS6OiEizcs0M\n1cmD0gDIzi9JcElERJqfa8I9OXgdVZ1UFRE3cFG4By61V6JwFxEXcE24JwVb7iXlFQkuiYhI83NN\nuHs9Bp/HqOUuIq7gmnCHQL+7+txFxA3cFe5+r7plRMQVXBXuSV4PJWVquYuI87kq3JP9WjxMRNzB\nXeHuU8tdRNzBZeGuPncRcQdXhbsutScibuGqcFe3jIi4hfvCXePcRcQFXBXuSZrEJCIu4apw1wlV\nEXELl4X74W4Zay0FJeUJLpGISPNwVbgnRYT7v5fsZMhdH/JNTkGCSyUiEn+uCvdknzfc5/7R2j0A\npGcr3EXEeVwV7m1TfBSWllMeMdbdGJPAEomINA9XhXvXdslYC7e9tZp5G7IBULSLiBO5LtwB/r0k\nI7xNDXcRcSJXhfvwXh0SXQQRkSPCVeHeNTWFgd3aRW0rq7AJKo2ISPNxVbhDIOAjaSExEXEi14V7\nWrDfPUTLEYiIE7kv3Ku23BXuIuJArgv3rqlVW+5aa0ZEnMd14d6pTXS4F5ZW8GlwzLuIiFO4Ltw7\ntPZH3X/ow41c+cLXLErfm6ASiYjEn+vCvVv7lJjbi8vUPSMizuG6cD+uS1seu3R4te2prfwx9hYR\naZlcF+4AU4Z2T3QRRESalSvD3eepvqBMuWaqioiD1CvcjTHnGmM2GmPSjTHTYzw+wRiTa4xZEfy5\nM/5FjZ9Yy/zO/HLbES+HiEhz8dW1gzHGCzwFTAYygK+NMe9aa9dV2fVza+35zVDGI2LOmt3s3F9E\nr2NaJ7ooIiJNVp+W+ygg3Vr7jbW2FHgNmNa8xUqMA0WliS6CiEhc1CfcewA7I+5nBLdVNcYYs8oY\nM8cYMzgupWtGb147ptq2A0VlCSiJiEj81dktU0/LgN7W2gJjzBTgbWBA1Z2MMdcA1wD07t07Tm/d\nOKf26Vht24FCtdxFxBnq03LPBHpF3O8Z3BZmrc2z1hYEb88G/MaYzlVfyFr7jLV2pLV2ZJcuXZpQ\n7PioOmqmqFQTmUTEGeoT7l8DA4wx/YwxScClwLuROxhjupngEBRjzKjg6+6Ld2Hjze+Nrn5RaXmC\nSiIiEl91dstYa8uNMTcAHwJe4Dlr7VpjzC+Djz8NXARca4wpBw4Bl1prj/qB4z6vgYhu9sIStdxF\nxBnq1ece7GqZXWXb0xG3nwSejG/Rml/V0e5quYuIU7hyhmpI1a8WkX3uby7NCJ9g3a8TrSLSwrg6\n3Kume2FpOS9+tZ2bXlvOza+v5ObXV7Jy50FOuW8u76zIjP0aIiJHIVeHe9WWe35xOb9/ew1vr9gF\nwJ68YlZlHARg8db9R7h0IiKN5+pwr2ruuj1R930eQ3FZ4BqrKT4vpeWVFJSoX15Ejn6uDve6BvR4\nPCZ8EY9WSR6ufOG/DLnrwyNRNBGRJnF1uD926QiG9mhf4+PLdxzk4bmbgEDLfVH64aH7azJzueRv\nX7Jw8171x4vIUSdeyw+0SJMGpTFpUBp78oo599EFta4t46sy4emOt9ewYudBFv9jMQDThsdabkdE\nJDFc3XIPSUtNqXPRsNLyyvBtay0VlUf9HC0RcTGFe9BzV4zkijF9a3y8pPzwGPiKSkt5PcJ9fVYe\n/9UoGxFJAIV70MSBadx9Yc0rFUdOcCosraCisrLaPtl5xfSdPouzHp4PwHmPfc7Ff/sy7mUVEamL\nwr0GVdd7f+GLbeHbJ9/zEZv2FEQ9Xl5RydLtBwDYklNY50gcEZHm5OoTqrFMHpTG3HV76HVMqwY9\nb/SMT9hbUBK+n3tIF/4QkcRRuFfx1A9P4VBpBTZi/uo1Z/TnmQXf1Pq8yGAHmL8xp1nKJyJSHwr3\nKpJ8HpJ8nqgVIju09jf4dW7614qo+9v3FeLzeujRoWHfCEREGkPhXoOkiHHtVa/Y1FDvrtzFr15d\nHr5/77TB3PnOWm6efAIrM3L54Wm9mDgwjVcW7+C2t1bTOsnLuYO78cglw5v0viLiXjqhWgNvRKDn\n5JfUsmfdIoMd4M531gLw8NxNfLx+DzNmbwDgtrdWA4GROf9ZXn3Wa3p2PnnF1fvy//nFNj7dkN2k\nMoqIsyjcaxC8aiAAJ3VPbdb36tg6qcbH0rMLqKi0PPnJZiY9soAf/DV6aOUjczdx17trufKFr+Na\npt25xeF1derjpa+20//WWVRqcpfIUUHdMnXo2NrPd0f04LT+nejUJomBv/8g7u/h88bu9lmTmcv5\nTyxk6rDuzFqVBcDGPfmsz8rjpO6pHCqt4PF5m2M+NzuvmLYpPlonNe6/ePSMeYwf0JkXf35avfZ/\n8IMNVFrYW1hC13YpjXpPgHW78kjyeTi+a9tGv4aIqOVeqzevHcMHN52BMYYeHVqR4vcysFu7uL+P\n12PYsDuv2va1u3IBwsEect5jnwM1D7ectSqLUX+cxyV/+6pR5QmN0f988956Pyd00nlrTiGHSht/\nLdopj3/OpEc+a/TzRSRA4V6LU/t0JC01uhXas2PruL+Pz2N4cM6Gatv3FtR8eb/KShsz3HfsK+L6\nV5YBsDozN+qxg0WHX291Ri6Pfrwp5ms3Zt2cdsmBcL/kma8Ydk/0sshlFZWUV1Sf0SsizUfh3kAP\nX3wyd0w9KeZjV4zpy6b7zyPFX/3XWtsQSJ/XE7P7ZMXOgzU+p/9ts/nbgi1R2/5v7ibOeOjTqG2v\nL9kJwJzVWQy/dy5/mLWOxd/s47t/WcSjH2+mrErobttbSF5x9QuSzN+YzTc50bNyV+48yHsrd1Fc\nVhHVtVRWcfjgcMfbqxlw+xymPr6wxrpI/ZRXVLJjX1GiiyFVbNydz+7c4kQXoxqFewO1b+Xn8tF9\nwvfvnXZ4PZpfnTWAJJ+HDfedV+15V4/vV+Nrzl23h1mrs2Jur81/lkWPqHksRv/7LW+sIuNAER8F\nX+vvn2/lkme+Ci98VhhxZam/zt/ChD/P55qZS8LbikrL+WTDHq54/msmPhzdXTLtqUXc+OpyfvOv\nFVGji0Lmb8zmpa92AIFzBbVZsfNgtQNNfVRUWib+eT7vr9rV4OdWtbegpFoXWMiBwtJqJ4t37Cvi\nkw01/x/FewmKP87ewBkPfUp2Xv2DZHVGLvsKmjbaS2p3zqMLGD1jXqKLUY3CvRFS/F6G9EjlTxcN\n48ej+3Byrw4AtEn21vicn5ze9wiVrrrrXl5GXg3988PvncuLX20HAidFAZYE18gB+NWrK7h65tJq\nz4vsZpm7bg9eUz3cr3g+egRPenbsgN918BDfeWoR174U/T7T31zFFc//FwgE5b+X7ORfX++ICtmi\n0nK+2VvIb99YFfO1G+IXLy7l+leWsb8wujvsYFEpI+6by0MfbYzaPvHh+fzshSXE8smGPfS7dTab\n6jioNcSi9MA5kP1FNXfXVXXBkwuZ8vjncSuDtBwK90Z6/8bxXDyyF8YYXvr5KN67YRzJvuhwH3zs\n4SGUniZOhGqKVRm5zKtlHPzT87fU+NjH6/dE9cGHgq8kYn378kpLZZVWat/ps6q91qRHFsR8j9DS\nDR+vP1zGa19aymtf72T+xhyKyypYvvMgv31jFb97czX3vr+OvtNn8eWWfeF19ssrbfgEdFlFJafP\nmMf5TxwOtfKKSh6Ys4HsvGLueHs1O/dHd29UVloyDgS2bdqTz9a9heHHDgbX+p9T5dtV6NvP/I3R\nv9u1u3LDob8s4kAZyw+e/oKp9Qzf0PGzvudEQgfBPXkl3P3uWnLruGaBOIuGQsZBuxQ/Q3tGX65v\nw33n4jGGE+6Yk6BS1V/mwUPhFS3r8umGbL5/as9qY+CX7aj5/ECk4rIKUvzRB8GqLWWAOWt2h29f\nPXNJ1Mid0Aqdl/398Gig0vJKpj6+kLMHpdGvSxuycovJyi2mvKISn9fDJxuyefqzLcxencWO/UVs\nyMrnjWvHUFZRyR9nr+f9VVnhmciXPhN43a0zpmCMYXvwQFBTpF7x/NfM/c0ZDEgLjKS67JnD5aor\nhr/eVvfvfen2Azz7+TeEjp8xVpuOqTBiCY0XvthGRaXlvu8MIbeojCmPf85ffnRK+FunOI9a7s0k\nxe8lyRf96x17fKcmv+6PTutdbdv4AZ2b/Lrf/+sX9drv5tdX8vi8zfz5o9gjbeqSefBQ+PY/v9jG\nMwu2cKCOboaGDMn8aN0e/vbZ4UXeioMt+zXBkUPZ+YH+6o278+k7fRYDbp/D84u2kZNfQlaVk2IH\nisqw1vLT5wJdQ1W/nUS67O9fhU+qFdUwFLS8opLVGbkxH4PACepnFlT/FnXtS0uZs2Y3+woD33Ai\nLxxTVXFZBct2HODDtbvZV2W0VWl5JZWVlpPv/YjMg4eY9tSiGrvKImXnF3PhkwvJyj1U574hBSXl\nMes6ZsY8nv388P9PWUVlgybLNUVxWQV9p8/iqn/WPuGvtLySP8xax4EYjY6WROF+BM382WkxTzzW\n5uxBaTx+2Yjw/SlDu1fbZ/CxNV/kuzk8MncTr/53R6Oee+c7a5j8yGc8MW8zd727lj/O3sADMYaB\nxktRaTkVlZbHP0kHoLgsEPb5JdVHBFX1P/9eEbVfZIt5TZVhpnsLShk9Yx7W1nyVroc+3MgFTy6s\nMVCnPbWIP87eUO1ErCfYHxPqClux8yDWWrLzi7n//XVR5z8e/GAD3/vLF/zixaVM+PP8qNdZmL6X\nD9bujtp23/vrY5YlJDA7Op1VGbnM/DJwbuabnILwAWbb3sLwif+P1u7m+UVbyS0q44ZXlnHBkwsp\niPj9WWvZlVvM/bMOv+flzy6ucWLgpj35WGspLClv1Mn2qmbMDrxvZPdfLHPWZPH3z7eGz0HV5O3l\nmazKqN831vTs/HDD4khRt0wzmzK0G8e2DwyD9HoMrfze8B/8yrvO5uR7Por5vP5d2vBNTiGTTkrj\nwpOPJT27gO37ChlzXCdumjSARz8+PDKmtlEZV4zpS3Z+MbNXR3+oh/ZoX20cfFMleT2U1vEhXJS+\nDwisqxOyJ6/5RnMUl1ayKKv+Lf9I8zfm8K37Pw7fzzx4iEXpe9lfWMqNVdYLCtmSUxh1v7CknIc+\n3MCNEwfw8uLAAXHSIws4rksbXrhyVHi/yNbsobIKdu4/xM79RUwalBbuaw+NbLp/1npG9O7I3xd8\nwwdrd9O+lZ8fjOxFt/YptQ7Jyzx4iOteXha1ra4JZ4/N2xwO9fKKSnLyS5j48Gf89PQ+3DNtSPgA\ncuPE43kieAC95711tEkKdL0NuetDts6YwqY9BfTtHD1HxFrL4uBlKNdk5vLr15bzz5+N4o2lGXy4\ndg/rs/J49JLh3PSvFYwf0Jm01BRG9T2Gi7/VC4B3VmTy0lfbef2X0RfW2V9YSmqKD5/Xg7U2vJRI\nxoH6ffMInceJvG5yLFVXfo0l8+AhcvJL+M5TiwB49icjOa5rW/p1blOvsjSFwr2Z/eVHp0bd79mx\nFRt25zP9vIG0b+Xn0UuGk5NfwoLNOSzZdoBDwa+oz/5kJNe9vIxJg9IA+J/JJ4Rf46ZJJ0SFe9Xu\ngj6dWrN9XxEvX3UaY48PdNnc/tZqPtuUE/4Df/TS4Zz1cMNngp7ap2ON/fMLf3cm8zfm8Ns3mz5y\nJV7OeOhTJpzYpdHPL6nyAf/Rs4tr3b+gyjeCF77YRsaBQ6zOzIt6bEtOIeP/dHhOQmRrdl9BKec8\nGjj5fP2Zx4W7iyK/EGzJKQi3wh+eu4mH525iQNe2dGpb8zpFsfx3237mrM5i7IDO/P7tNVw9vj9X\nz1zCc1d8i9WZuVHLW+zOK+F/X18JBEZURY5aCgV7SGHEQeO8xz5nw+7q31Yih+7+/p01bMkpZNyD\n0fM0VgZbxqGuuTeWZtChtZ+zB3fj168FwrWsohJ/cBXX3KIyTrlvLtdNOI5DZRXMXbeHz245E6/n\n8LmTqm58dTn9O7fhN8HPWOjjZGKMAAuJ1aBavuMAI3p3JL+4DK/H0DrJx9gHPona56rgMOPnr/wW\nZ57YtcbXjweTqMvBjRw50i5ZEnsYmZPtySvm8817uejUnjEfD40y2fbA1FpfJ3I0ys/H9eMfC7dy\nXJc2bMkp5KJTe/Kn7w+LOUIn9LwVd07m620HuDr4x3bO4DQ+XBs9ZvuEtLbVLie47YGpTHjoU7ZV\nmUyT/ofz8AU/YLFGyrhFuxQf+TEmgTVEpzZJ7Etwf+/gY1NZu6v6khjxsu2BqQy568PwAa9nx1b1\nbllD9W+9y34/mWPaJPGvr3fwuzdXhxs4EKjLK1ePjto/8vMV+nu9bFRvissqGNazPfe8t46pQ7vz\n4EXDsNbSyu8N/31D4BvPSXdW707a9sBU+k6fRee2Sbx13dioA3ikW845kevPPL7e9Y1kjFlqrR1Z\n135quR9haakpNQZ7Y7Tye+nQKjD1P9R6aZ3krXHoZbtkH/kl5aSm+Jk8KI23rhvDm8syKA/OKo38\nkP37F6ezYudBduwvYuLAruFZtsN6dmDbvsC2U/t05PlF26L+8N++fixrMnNZuDm6j/eME7qwYFPt\nV6i6eGRPrIXXl2ZEbU/2eZj1q3Es237wqPpmUFVTgx1IeLADzRrsIck+D6H5VQ0JdqBad+Yp981l\nyR2T+N2bgWWzt0c0PtbuyqvWN37NzCUcLCrj2A6HlxcJnUcKnUOYtTorPLnw0m/1Ysb3hvLQhxu5\n6NSetE2OHZ2PBOdC7C0orTHYIXopkOaicD/KTD9vIMN61n2CdGC3dmzck8/8WybQobU/3GLcsDu/\n1pUg37lhLKszc8PhP6J3R0b07sg97wXWmL/0W71o38rPv5dk0KF1EhNifHV84PtDuXx0H0b1Owag\nWgtkeK8ODO/VgZ3BceMn9+rAtd8+jrMHpdH/ttlR+97/nSHc8faa8P1eHVtz41kDWJi+l6zcYt74\n5em0b+WnY5skOrdN5viu7ejYJol9BSVM/8/qmHX8xRn9uXx0H8b/6VO6t0+pNgom0ob7zuXLLfua\nvGTysJ7tWRUxOmT8gM4NGuXTXE7u2Z6VtYzQGdG7A8vrOYw1nsb/6ZO4H8RGRpwfqWp7lW+aH9Uy\n+7tq1xrAa1/vxOMxvLJ4B3+Zv4Uu7ZJjPvfxKt1TNbltSuwlTOJJo2WOMr/89nGMOa7uoY0f3HQG\nW2dMJS01hWSflyvG9uPy0X04a2BXrqplqYP+XdoybXiPattD247v2o4fn96X924cV+NrtE7yhYO9\nVsEev/OGdOPcId2qfZv4649OqTa0syzYjxsaATSweyoD0trRue3hD9PkQWlcOqo3j1x8csy3vX7i\n8fQ6pjV3XzCIv/34VD64aTyj+x8ub+gbyLThx5Li90ZdDL33MTUvDPe9Uw7/3l67ZjQ3R5wHeeu6\nsVH7fifG7/jNa8fw/o3j+GGwzgO6tuWB7w2t8rxja3z/mnRLTeGzWybEfGxYz9rHsb/489O458LB\nte5TmylDuzXqeTv3195Sn3RSWqNetyaRDYjGemXx4RFiTbmAz3NXjKy1Pz9eFO4O0rFNEv+44ltR\nQVhfw3t1YNXdZ3PO4Ph9qCYHTwaPO/7wwepHp/WmY2s/X946kfOGdscYw7YHpjLn1+MBwu//6KXD\nefeGsTX8IA18AAAJzUlEQVR+/QX43ik9o4J58W1n8fXtk0hNCXRTXTG2H8N6dmBgt1ReuHIUH9w0\nnlevHs05gwOBFJpB3L/z4bXjX77qNF6qYQ37yO600f07ceW4fvTp1Jp7pw3G6zFMP29g+HG/z8OC\nW86Mev6IXh0Y0qM9f/zuUO7/zhBm/nwUkwalcUybwEnQ26ecxD3ThjAgxlr2X946kfat/Nx1wSAW\n/u5MPvrNGXQOnjx98KJh9OlUffRFss/D7VNPInRMXXLHJP737BOi9mmb7GvS/ItBzXQhm/+7JPaB\nuy6n9O5A/4iRKI2ZAzKkR8PrNLRH/YcjV11ptrnUq1vGGHMu8BjgBZ611j5Q5XETfHwKUARcYa1d\nVu2F5KgWCsV4Gdn3mGonhv/w3aH84btDq+17UvfUqH3bJvvqbHUCvH/DeN5ansHLi3dwTJuk8HmH\nqgJr8Qc+tAeKSnlu0dbwjFKPx7D895NpleQlxe8NT7QKnZQ7qXsq6dn5DOqeykMXDQu3utom+/gs\nIsAj3/vknu3p3ak1q+8+m6F3fxR+n5DIxeeW/X5yVFnfvn4sg++KXja5e/tWrLzr7Kht8285k+Ky\nivDB/Lwh3ejevhU/G9eXL7fs45Q+HUnxe1l/37nsLSilc9tkbpg4gPJKy8wvt/NEcP5Eaqvo//fr\nJhzHnDW7o5ZggECXYWhOwj0XDmZ/YSlXn9GfP3+0iR+c2pPXl2aQ4vfwizOOi7mI3V0XDGJR+j5+\ne+6JnJDWjn0FJZwaoyvl3mmDaZfib/BJVgis4XT+sO4Ul1fy4pfb+fm4flGzxLfOmMLoGfOiht9+\neetEPtmQzQOzN5BfUs4714/juIjuw9umDOSPs6uPeW+X4uPVq0fz0drd/GxcP3712gqmnzswvJbP\nO9eP5Z9fbqu2wF/7VvH9nNWkztEyxhgvsAmYDGQAXwOXWWvXRewzBbiRQLifBjxmra31Ej5uHS0j\nR4etewtrHGtcWWl56tN0fjS6Dxt35zOid4dqSybEkpV7iAueWMirV48OHzggsOBX7qGymBPQatJ3\n+ix6dmzFbVNOYk1mLr89d2DdT2qC91bu4owBXWgfvOjKbW+t5pXFO8JdT9efeTwej+GdFZmckNYu\n6tKTuYfKaJPkxesxGGNYtysvarGyN68dw/BeHWJO4Bt294ec1r8Td184mDMfmk9pRWX4IL86I5eZ\nX27j/JOPZfCxqdX61D+4aTyt/T4embuRt1fsIjXFx5I7JlebGR45emvbA1MpKa/ghUXbmDFnAxNO\n7BKeb1BcVsHu3GL6dm7DI3M38fi8zTx26XCmDe/BTa8t5+0VgZVHn778FH750jKuHt+P26cOqlan\nNZm5fLohmxvPGkB5RSWLtuyjoLicscd3Yn1WPqcf17SZ6vUdLVOfcD8duNtae07w/q0A1toZEfv8\nDZhvrX01eH8jMMFaG3v9VBTuIrVZlXGQ7u1b1XjirrmVlleyY39Roy53aK3lHwu38s6KXVw8sic/\nrueKqAcKSymvtDXWORTS827+Nuuz8jh/2OHzE2sycxl8bGrMvuxHP97Eox9v5s7zB/GzcYHzUeUV\nlfzfx5v46Zi+9b4s5A///hVfbNnHW9eNCf/fNHTGeTzEM9wvAs611l4VvP9j4DRr7Q0R+7wPPGCt\nXRi8Pw/4nbW2xvRWuItIQ2zfV8i2fUV8+4TGT0prij15xcz8chs3Tz4xoau8HpXj3I0x1wDXAPTu\nXX0BLBGRmvTp1CbmieMjJS01hVvOad7usXiqz2iZTKBXxP2ewW0N3Qdr7TPW2pHW2pFduiTm6Csi\n4gb1CfevgQHGmH7GmCTgUuDdKvu8C/zEBIwGcmvrbxcRkeZVZ7eMtbbcGHMD8CGBoZDPWWvXGmN+\nGXz8aWA2gZEy6QSGQl7ZfEUWEZG61KvP3Vo7m0CAR257OuK2Ba6Pb9FERKSxNENVRMSBFO4iIg6k\ncBcRcSCFu4iIAyXsSkzGmBxgeyOf3hlI/GLZzU/1dB631FX1bD59rLV1ThRKWLg3hTFmSX2m37Z0\nqqfzuKWuqmfiqVtGRMSBFO4iIg7UUsP9mUQX4AhRPZ3HLXVVPROsRfa5i4hI7Vpqy11ERGrR4sLd\nGHOuMWajMSbdGDM90eVpCmNML2PMp8aYdcaYtcaYXwe3H2OMmWuM2Rz8t2PEc24N1n2jMeacxJW+\nYYwxXmPM8uCFXRxZRwBjTAdjzBvGmA3GmPXGmNOdWFdjzG+Cf7NrjDGvGmNSnFBPY8xzxphsY8ya\niG0Nrpcx5lRjzOrgY4+bWJeIam7W2hbzQ2BVyi1AfyAJWAkMSnS5mlCf7sApwdvtCFyrdhDwJ2B6\ncPt04MHg7UHBOicD/YK/C2+i61HPuv4P8ArwfvC+4+oYLP8/gauCt5OADk6rK9AD2Aq0Ct7/N3CF\nE+oJnAGcAqyJ2NbgegH/BUYDBpgDnHek69LSWu6jgHRr7TfW2lLgNWBagsvUaNbaLGvtsuDtfGA9\ngQ/ONAIhQfDf7wRvTwNes9aWWGu3ElhiedSRLXXDGWN6AlOBZyM2O6qOAMaY9gTC4R8A1tpSa+1B\nHFhXAivKtjLG+IDWwC4cUE9r7QJgf5XNDaqXMaY7kGqt/coGkn5mxHOOmJYW7j2AnRH3M4LbWjxj\nTF9gBLAYSLOHL3ayG0gL3m6p9X8U+C1QGbHNaXWEQOstB3g+2AX1rDGmDQ6rq7U2E/gzsAPIInBx\nno9wWD0jNLRePYK3q24/olpauDuSMaYt8CZwk7U2L/Kx4JG/xQ5pMsacD2Rba5fWtE9Lr2MEH4Gv\n9H+11o4ACgl8jQ9zQl2Dfc7TCBzMjgXaGGMuj9zHCfWMpSXVq6WFe72u1dqSGGP8BIL9ZWvtf4Kb\n9wS/2hH8Nzu4vSXWfyxwoTFmG4FutInGmJdwVh1DMoAMa+3i4P03CIS90+o6Cdhqrc2x1pYB/wHG\n4Lx6hjS0XpnB21W3H1EtLdzrcz3XFiN4Bv0fwHpr7SMRD70L/DR4+6fAOxHbLzXGJBtj+gEDCJy4\nOWpZa2+11va01vYl8P/1ibX2chxUxxBr7W5gpzHmxOCms4B1OK+uO4DRxpjWwb/hswicL3JaPUMa\nVK9gF06eMWZ08Pfzk4jnHDmJPjvd0B8C12rdRODM9O2JLk8T6zKOwFe8VcCK4M8UoBMwD9gMfAwc\nE/Gc24N130gCzsA3sb4TODxaxql1HA4sCf6fvg10dGJdgXuADcAa4EUCI0ZafD2BVwmcRygj8E3s\n542pFzAy+LvZAjxJcMLokfzRDFUREQdqad0yIiJSDwp3EREHUriLiDiQwl1ExIEU7iIiDqRwFxFx\nIIW7iIgDKdxFRBzo/wH97Tz0aeL3GgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c308450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we instatiate the model for our data\n",
    "model = mx.mod.Module(\n",
    "    mlp,                             # Use the network we just defined\n",
    "    context = mx.cpu(0),             # Run on CPU 0\n",
    "    data_names = ['data'],           # Provide the name of 'data'\n",
    "    label_names = ['softmax_label'], # Provide the name of 'label\n",
    "    )\n",
    "# bind the shapes to the module\n",
    "model.bind(data_shapes=train_iter.provide_data,\n",
    "           label_shapes=train_iter.provide_label)\n",
    "\n",
    "# initialize the logloss evaluation metric\n",
    "cross_entropy_evaluator = LogLoss()\n",
    "\n",
    "# call fit to make sure you can achieve 0 loss\n",
    "model.fit(\n",
    "    train_data = train_iter,\n",
    "    eval_data = test_iter,\n",
    "    num_epoch = 3,\n",
    "    eval_metric = cross_entropy_evaluator,\n",
    "    initializer = mx.init.Orthogonal(0.25),\n",
    "    optimizer_params = {'learning_rate':0.1, 'momentum': 0.9, 'wd':0.00001},\n",
    "    batch_end_callback = log_train_metric(500),\n",
    ")\n",
    "\n",
    "plt.plot(cross_entropy_evaluator.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate annealing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we've established a first learning rate, we must now decide if we put the learning rate on a type of decay-schedule, especially if we have larger models. This is done because sometimes the model is not able to reach the true minimum of the loss due to the step size being large and the gradient not being able to settle down into narrower parts of the loss function. \n",
    "\n",
    "One common way people deal with the above problem is to anneal the learning rate is via some sort of step decay where one simply reduces the learning rate every $n$ steps. One simple heuristic is to reduce the learning rate in half when improvement on the validation set stops. Problems can still arise, however. If decay your learning rate too slowly, you'll  proceed with very little improvement in loss reduction as the gradient will bounce around unable to get into the smaller crevasses and if you decay to aggressively, you'll waste computation time simply moving too slowly.\n",
    "\n",
    "MXNet gives you an easy package to implement your learning rate strategies, found in the <code>mxnet.lr_scheduler.LRScheduler</code> class. In order to implement the common decay strategy, we'll use the <code>FactorScheduler</code> to decay our learning rate by <code>base_lr * pow(factor, floor(num_update/step))</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reduce the learning rate by a factor for every *n* steps.\n",
    "# It returns a new learning rate by::\n",
    "# base_lr * pow(factor, floor(num_update/step))\n",
    "lr_scheduler = mx.lr_scheduler.FactorScheduler(\n",
    "                    step = 5000,\n",
    "                    factor = 0.1)\n",
    "\n",
    "# initialize the logloss evaluation metric\n",
    "cross_entropy_evaluator = LogLoss()\n",
    "\n",
    "# fit our model\n",
    "model.fit(\n",
    "    train_data = train_iter,\n",
    "    eval_data = test_iter,\n",
    "    num_epoch = 10,\n",
    "    eval_metric = cross_entropy_evaluator,\n",
    "    initializer = mx.init.Orthogonal(0.25),\n",
    "    optimizer_params = {'learning_rate':0.1, 'momentum': 0.9,\n",
    "                        ##### Learning Rate Sheduling ######\n",
    "                        'lr_scheduler': lr_scheduler},\n",
    "    batch_end_callback = log_train_metric(500),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a full implementation of the all the steps we've discussed so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Already bound, ignoring bind()\n",
      "INFO:root:Iter[0] Batch[0] Train-LogLoss=2.302969\n",
      "INFO:root:Epoch[0] Train-LogLoss=0.360535\n",
      "INFO:root:Epoch[0] Time cost=5.490\n",
      "INFO:root:Epoch[0] Validation-LogLoss=0.121222\n",
      "INFO:root:Iter[1] Batch[0] Train-LogLoss=0.130813\n",
      "INFO:root:Epoch[1] Train-LogLoss=0.094354\n",
      "INFO:root:Epoch[1] Time cost=4.320\n",
      "INFO:root:Epoch[1] Validation-LogLoss=0.082275\n",
      "INFO:root:Iter[2] Batch[0] Train-LogLoss=0.096660\n",
      "INFO:root:Epoch[2] Train-LogLoss=0.060938\n",
      "INFO:root:Epoch[2] Time cost=8.021\n",
      "INFO:root:Epoch[2] Validation-LogLoss=0.073913\n",
      "INFO:root:Iter[3] Batch[0] Train-LogLoss=0.075060\n",
      "INFO:root:Epoch[3] Train-LogLoss=0.042938\n",
      "INFO:root:Epoch[3] Time cost=5.375\n",
      "INFO:root:Epoch[3] Validation-LogLoss=0.069780\n",
      "INFO:root:Iter[4] Batch[0] Train-LogLoss=0.058862\n",
      "INFO:root:Epoch[4] Train-LogLoss=0.030366\n",
      "INFO:root:Epoch[4] Time cost=3.296\n",
      "INFO:root:Epoch[4] Validation-LogLoss=0.066718\n",
      "INFO:root:Iter[5] Batch[0] Train-LogLoss=0.038986\n",
      "INFO:root:Epoch[5] Train-LogLoss=0.021025\n",
      "INFO:root:Epoch[5] Time cost=3.871\n",
      "INFO:root:Epoch[5] Validation-LogLoss=0.064498\n",
      "INFO:root:Iter[6] Batch[0] Train-LogLoss=0.027413\n",
      "INFO:root:Epoch[6] Train-LogLoss=0.015761\n",
      "INFO:root:Epoch[6] Time cost=4.447\n",
      "INFO:root:Epoch[6] Validation-LogLoss=0.069684\n",
      "INFO:root:Iter[7] Batch[0] Train-LogLoss=0.015622\n",
      "INFO:root:Epoch[7] Train-LogLoss=0.014998\n",
      "INFO:root:Epoch[7] Time cost=4.965\n",
      "INFO:root:Epoch[7] Validation-LogLoss=0.078902\n",
      "INFO:root:Iter[8] Batch[0] Train-LogLoss=0.035286\n",
      "INFO:root:Epoch[8] Train-LogLoss=0.013211\n",
      "INFO:root:Epoch[8] Time cost=5.314\n",
      "INFO:root:Epoch[8] Validation-LogLoss=0.089004\n",
      "INFO:root:Iter[9] Batch[0] Train-LogLoss=0.022633\n",
      "INFO:root:Epoch[9] Train-LogLoss=0.013171\n",
      "INFO:root:Epoch[9] Time cost=5.595\n",
      "INFO:root:Epoch[9] Validation-LogLoss=0.090771\n",
      "INFO:root:Iter[10] Batch[0] Train-LogLoss=0.009464\n",
      "INFO:root:Epoch[10] Train-LogLoss=0.011697\n",
      "INFO:root:Epoch[10] Time cost=7.828\n",
      "INFO:root:Epoch[10] Validation-LogLoss=0.095450\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wTBJTyn7prVmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118ef2c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Result: 7\n"
     ]
    }
   ],
   "source": [
    "#############################################################\n",
    "## Set up our mxnet model to showcase the tips and tricks  ##\n",
    "#############################################################\n",
    "%matplotlib inline\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss\n",
    "from mxnet.callback import log_train_metric\n",
    "\n",
    "# call our logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Network declaration as symbols.\n",
    "data = mx.symbol.Variable('data')\n",
    "fc1  = mx.symbol.FullyConnected(data = data, name='fc1', num_hidden=512)\n",
    "act1 = mx.symbol.Activation(data = fc1, name='relu1', act_type=\"relu\")\n",
    "fc2  = mx.symbol.FullyConnected(data = act1, name = 'fc2', num_hidden = 512)\n",
    "act2 = mx.symbol.Activation(data = fc2, name='relu2', act_type=\"relu\")\n",
    "fc3  = mx.symbol.FullyConnected(data = act2, name='fc3', num_hidden=10)\n",
    "mlp = mx.symbol.SoftmaxOutput(data=fc3, name='softmax')\n",
    "\n",
    "# Now we fetch MNIST dataset, add some noise, \n",
    "# permutate, and assign the examples to be used on our network\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_pca = PCA(n_components=70).fit_transform(mnist.data)\n",
    "noise = np.random.normal(size=mnist_pca.shape)\n",
    "mnist_pca += noise\n",
    "np.random.seed(1234) # set seed for deterministic ordering\n",
    "p = np.random.permutation(mnist_pca.shape[0])\n",
    "X = mnist_pca[p]\n",
    "Y = mnist.target[p]\n",
    "X_show = mnist.data[p]\n",
    "\n",
    "# This is just to normalize the input to a value inside [0,1],\n",
    "# and separate train set and test set\n",
    "X = X.astype(np.float32)/255\n",
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "X_show = X_show[60000:]\n",
    "Y_train = Y[:60000]\n",
    "Y_test = Y[60000:]\n",
    "\n",
    "# set batch size\n",
    "batch_size = 200\n",
    "train_iter = mx.io.NDArrayIter(X_train, Y_train, batch_size=batch_size)\n",
    "test_iter = mx.io.NDArrayIter(X_test, Y_test, batch_size=batch_size)\n",
    "\n",
    "# A quick work around to prevent mxnet complaining the lack of a softmax_label (0.9.4 only)\n",
    "train_iter.label =  mx.io._init_data(Y_train, allow_empty=True, default_name='softmax_label')\n",
    "test_iter.label =  mx.io._init_data(Y_test, allow_empty=True, default_name='softmax_label')\n",
    "\n",
    "# the cross-entropy loss function for mxnet evaluation callback\n",
    "class LogLoss(mx.metric.EvalMetric):\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "        super(LogLoss, self).__init__('LogLoss')\n",
    "\n",
    "    def update(self, labels, preds):\n",
    "        label_weight = labels[0].asnumpy()\n",
    "        preds = preds[0].asnumpy()\n",
    "        loss = log_loss(label_weight, preds)\n",
    "        self.loss.append(loss)\n",
    "        self.sum_metric += loss\n",
    "        self.num_inst += 1\n",
    "\n",
    "\n",
    "# Here we instatiate the model for our data\n",
    "model = mx.mod.Module(\n",
    "    mlp,                             # Use the network we just defined\n",
    "    context = mx.cpu(0),             # Run on CPU 0\n",
    "    data_names = ['data'],           # Provide the name of 'data'\n",
    "    label_names = ['softmax_label'], # Provide the name of 'label\n",
    "    )\n",
    "\n",
    "# bind the shapes to the module\n",
    "model.bind(data_shapes=train_iter.provide_data,\n",
    "           label_shapes=train_iter.provide_label)\n",
    "\n",
    "# initialize the logloss evaluation metric\n",
    "cross_entropy_evaluator = LogLoss()\n",
    "\n",
    "# learning rate scheduler            \n",
    "lr_scheduler = mx.lr_scheduler.FactorScheduler(\n",
    "                    step = 5000,\n",
    "                    factor = 0.1)\n",
    "\n",
    "# fit the model - notice the first loss is \n",
    "#\"INFO:root:Iter[0] Batch[0] Train-LogLoss=2.302969\", right where\n",
    "# we want it to be\n",
    "model.fit(\n",
    "    train_data = train_iter,                    # Define training data\n",
    "    eval_data = test_iter,                      # Define testing/evaluation data\n",
    "    num_epoch = 11,                             # 10 training epochs\n",
    "    eval_metric = cross_entropy_evaluator,      # use Cross Entropy as the eval metric\n",
    "    initializer = mx.init.Orthogonal(0.25),     # Use an Orthogonal initializer for our weights\n",
    "    optimizer = 'adam',                         # Use Adam as our optimizer\n",
    "    optimizer_params = {                        # Define our optimizer's params\n",
    "        'learning_rate':0.0009,                 # Start the learning rate at .1\n",
    "        'wd':0.00001,                           # Set the weight decay\n",
    "        'lr_scheduler': lr_scheduler            # User our learning rate scheduler\n",
    "    },\n",
    "    batch_end_callback = log_train_metric(500), # Use the callback function to tell us \n",
    ")                                               # how well the model is performing after each epoch\n",
    "\n",
    "# show the data\n",
    "plt.imshow((X_show[0].reshape((28,28))*255).astype(np.uint8), cmap='Greys_r')\n",
    "plt.show()\n",
    "print('Predicted Result: {}'.format(model.predict(test_iter)[0].asnumpy().argmax()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
