{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Localization and Detection\n",
    "\n",
    "<img src='files/obj/LocalizationDetection.png'>\n",
    "\n",
    "## Localize objects with regression\n",
    "\n",
    "Regression is about returning a number instead of a class, in our case we're going to return 4 numbers (x0,y0,width,height) that are related to a bounding box. You train this system with an image an a ground truth bounding box, and use L2 distance to calculate the loss between the predicted bounding box and the ground truth.\n",
    "\n",
    "<img src='files/obj/LocalizationRegression1.png'>\n",
    "\n",
    "Normally what you do is attach another fully connected layer on the last convolution layer\n",
    "\n",
    "<img src='files/obj/LocalizationRegression2.png'>\n",
    "\n",
    "\n",
    "This will work only for one object at a time.\n",
    "Some people attach the regression part after the last convolution (Overfeat) layer, while others attach after the fully connected layer (RCNN). Both works.\n",
    "\n",
    "### Comparing bounding box prediction accuracy\n",
    "\n",
    "Basically we need to compare if the Intersect Over Union (ioU) between the prediction and the ground truth is bigger than some threshold (ex > 0.5)\n",
    "\n",
    "<img src='files/obj/Intersection-over-Union-IoU-of.png'>\n",
    "\n",
    "## R-CNN\n",
    "\n",
    "RCNN (Regions + CNN) is a method that relies on a external region proposal system.\n",
    "\n",
    "<img src='files/obj/RCNNSimple.png'>\n",
    "\n",
    "\n",
    "The problem of RCNN is that it's never made to be fast, for instance the steps to train the network are these:\n",
    "\n",
    " * Take a pre-trained imagenet cnn (ex Alexnet/ResNet/GoogleNet/Inception/VGG/etc.)\n",
    " * Re-train the last fully connected layer with the objects that need to be detected + \"no-object\" class\n",
    " * Get all proposals(=~2000 p/image), resize them to match the cnn input, then save to disk.\n",
    " * Train SVM to classify between object and background (One binary SVM for each class)\n",
    " * BB Regression: Train a linear regression classifier that will output some correction factor\n",
    "\n",
    "### Step 3 Save and pre-process proposals\n",
    "\n",
    "<img src='files/obj/Step3RCNN.png'>\n",
    "\n",
    "### Step 5 (Adjust bounding box)\n",
    "\n",
    "<img src='files/obj/Step5RCNN.png'>\n",
    "\n",
    "\n",
    "## Fast RCNN\n",
    "\n",
    "The Fast RCNN method receive region proposals from some external system (Selective search). This proposals will sent to a layer (Roi Pooling) that will resize all regions with their data to a fixed size. This step is needed because the fully connected layer expect that all the vectors will have same size\n",
    "\n",
    "<img src='files/obj/Fast_RCNN.png'>\n",
    "\n",
    "Proposals example, boxes=[r, x1, y1, x2, y2]\n",
    "\n",
    "<img src='files/obj/Proposals.png'>\n",
    "\n",
    "<img src='files/obj/Fast_RCnn_Caffe_LastPart.png'>\n",
    "\n",
    "Still depends on some external system to give the region proposals (Selective search)\n",
    "\n",
    "\n",
    "### ROI Pooling Layer\n",
    "\n",
    "<img src='files/obj/RoiPoolingLayer.png'>\n",
    "\n",
    "It's a type of max-pooling with a pool size dependent on the input, so that the output always has the same size. This is done because fully connected layer always expected the same input size.\n",
    "\n",
    "<img src='files/obj/RoiPoolingLayerCaffe.png'>\n",
    "\n",
    "The inputs of the Roi layer will be the proposals and the last convolution layer activations. For example consider the following input image, and it's proposals.\n",
    "\n",
    "Input image\n",
    "\n",
    "<img src='files/obj/InImage.png'>\n",
    "\n",
    "Two proposed regions\n",
    "\n",
    "<img src='files/obj/InImageRegions.png'>\n",
    "\n",
    "Now the activations on the last convolution layer (ex: conv5)\n",
    "\n",
    "<img src='files/obj/Conv5_Activations.png'>\n",
    "\n",
    "For each convolution activation (each cell from the image above) the Roi Pooling layer will resize, the region proposals (in red) to the same resolution expected on the fully connected layer. For example consider the selected cell in green.\n",
    "\n",
    "<img src='files/obj/Conv5_Activation_and_Proposals.png'>\n",
    "\n",
    "Here the output will be:\n",
    "\n",
    "<img src='files/obj/Roi_PoolingLayer1.png'>\n",
    "\n",
    "<img src='files/obj/Roi_PoolingLayer2.png'>\n",
    "\n",
    "\n",
    "## Faster RCNN\n",
    "\n",
    "<img src='files/obj/Faster_Rcnn.png'>\n",
    "\n",
    "The main idea is use the last (or deep) conv layers to infer region proposals.\n",
    "Faster-RCNN consists of two modules.\n",
    "\n",
    "* RPN (Region proposals): Gives a set of rectangles based on deep convolution layer\n",
    "* Fast-RCNN Roi Pooling layer: Classify each proposal, and refining proposal location\n",
    "\n",
    "### Region proposal Network\n",
    "\n",
    "Here we break on a block diagram how Faster RCNN works.\n",
    "\n",
    "* Get a trained (ie imagenet) convolution neural network\n",
    "* Get feature maps from the last (or deep) convolution layer\n",
    "* Train a region proposal network that will decide if there is an object or not on the image, and also propose a box location\n",
    "* Give results to a custom (python) layer\n",
    "* Give proposals to a ROI pooling layer (like Fast RCNN)\n",
    "* After all proposals get reshaped to a fix size, send to a fully connected layer to continue the classification\n",
    "\n",
    "<img src='files/obj/RPN_Network.png'>\n",
    "\n",
    "### How it works\n",
    "\n",
    "Basically the RPN slides a small window (3x3) on the feature map, that classify what is under the window as object or not object, and also gives some bounding box location.\n",
    "For every slidding window center it creates fixed k anchor boxes, and classify those boxes as been object or not.\n",
    "\n",
    "<img src='files/obj/RPN_Sliding.png'>\n",
    "\n",
    "\n",
    "### Faster RCNN training\n",
    "\n",
    "On the paper, each network was trained separately, but we also can train it jointly. Just consider the model having 4 losses.\n",
    "\n",
    "* RPN Classification (Object or not object)\n",
    "* RPN Bounding box proposal\n",
    "* Fast RCNN Classification (Normal object classification)\n",
    "* Fast RCNN Bounding-box regression (Improve previous BB proposal)\n",
    "\n",
    "<img src='files/obj/FasterRCNNTrain.png'>\n",
    "\n",
    "### Faster RCNN results\n",
    "\n",
    "<img src='files/obj/FasterRCNNSpeedComparison.png'>\n",
    "\n",
    "Complete Faster RCNN diagram:\n",
    "\n",
    "this diagram represents the complete structure of the Faster RCNN using VGG16, I've found on a github project here. It uses a framework called Chainer which is a complete framework using only python (Sometimes cython).\n",
    "\n",
    "<img src='files/obj/Faster R-CNN.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
