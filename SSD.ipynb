{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multibox Single Shot Detector (SSD)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "<img src='files/obj/SSDModel.png'>\n",
    "\n",
    "The SSD detector differs from others single shot detectors due to the usage of multiple layers that provide a finer accuracy on objects with different scales. (Each deeper layer will see bigger objects).\n",
    "\n",
    "The SSD normally start with a VGG on Resnet pre-trained model that is converted to a fully convolution neural network. Then we attach some extra conv layers, which will actually help to handle bigger objects. The SSD architecture can in principle be used with any deep network base model.\n",
    "\n",
    "One important point to notice is that after the image is passed on the VGG network, some conv layers are added producing feature maps of sizes 19x19, 10x10, 5x5, 3x3, 1x1. These, together with the 38x38 feature map produced by VGG’s conv4_3, are the feature maps which will be used to predict bounding boxes.\n",
    "\n",
    "There the conv4_3 is responsible to detect the smallest objects while the conv11_2 is responsible for the biggest objects.\n",
    "\n",
    "<img src='files/obj/SSD_Diag1.png'>\n",
    "\n",
    "As shown on the diagram some activations are \"grabbed\" from the network and passed to a specialized sub-network that should work as a classifier and localizer. During prediction we use a Non-maxima suppression algorithm to filter the multiple boxes per object that may appear.\n",
    "\n",
    "<img src='files/obj/SSD_Localizer_Classifier.png'>\n",
    "\n",
    "## Anchor(Priors or Default boxes) concept\n",
    "\n",
    "Anchors are a collection of boxes overlaid on the image at different spatial locations, scales and aspect ratios that act as reference points on the ground truth images. It's like the Yolo idea where each cell on the activation map has multiple boxes.\n",
    "\n",
    "<img src='files/obj/Faster_R-CNN__anchor_boxes.jpg'>\n",
    "\n",
    "A model is then trained to make two predictions for each anchor:\n",
    "\n",
    "* 1) A discrete class prediction for each anchor\n",
    "\n",
    "* 2) A continuous prediction of an offset by which the anchor needs to be shifted to fit the ground-truth bounding box\n",
    "\n",
    "During training SSD matches objects with _default boxes _of different aspects. Each element of the feature map (cell) has a number of default boxes associated with it. Any default box with an IoU (Jaccard index) greater than 0.5 is considered a match.\n",
    "\n",
    "<img src='files/obj/grid_full.png'>\n",
    "\n",
    "Consider the image above, observe that the cat is has 2 boxes that match on the 8x8 feature map, but none on the dog. Now on the 4x4 feature map there is one box that matches the dog.\n",
    "\n",
    "It is important to note that the boxes in the 8x8 feature map are smaller than those in the 4x4 feature map: SSD grab some feature maps, each responsible for a different scale of objects, allowing it to identify objects across a large range of scales.\n",
    "\n",
    "For each default box on each cell the network output the following:\n",
    "\n",
    "* A probability vector of length c, where c are the number of classes plus the background class that indicates no object.\n",
    "* A vector with 4 elements (x,y,width,height) representing the offset required move the default box position to the real object.\n",
    "\n",
    "## Multibox Loss Function\n",
    "\n",
    "During training we minimize a combined classification and regression loss.\n",
    "\n",
    "<img src='files/obj/Loss1.png'>\n",
    "\n",
    "As Yolo the SSD loss balance the classification objective and the localization objective.\n",
    "\n",
    "### Localization Loss\n",
    "\n",
    "<img src='files/obj/Loss2.png'>\n",
    "<img src='files/obj/Loss3.png'>\n",
    "\n",
    "Classification Loss\n",
    "\n",
    "<img src='files/obj/Loss4.png'>\n",
    "\n",
    "Bellow we have the forward propagation of this loss using PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(self, predictions, targets):\n",
    "        \"\"\"Multibox Loss\n",
    "        Args:\n",
    "            predictions (tuple): A tuple containing loc preds, conf preds,\n",
    "            and prior boxes from SSD net.\n",
    "                conf shape: torch.size(batch_size,num_priors,num_classes)\n",
    "                loc shape: torch.size(batch_size,num_priors,4)\n",
    "                priors shape: torch.size(num_priors,4)\n",
    "            ground_truth (tensor): Ground truth boxes and labels for a batch,\n",
    "                shape: [batch_size,num_objs,5] (last idx is the label).\n",
    "        \"\"\"\n",
    "\n",
    "        loc_data, conf_data, priors = predictions\n",
    "        num = loc_data.size(0)\n",
    "        num_priors = (priors.size(0))\n",
    "        num_classes = self.num_classes\n",
    "\n",
    "        # match priors (default boxes) and ground truth boxes\n",
    "        loc_t = torch.Tensor(num, num_priors, 4)\n",
    "        conf_t = torch.LongTensor(num, num_priors)\n",
    "        for idx in range(num):\n",
    "            truths = targets[idx][:,:-1].data\n",
    "            labels = targets[idx][:,-1].data\n",
    "            defaults = priors.data\n",
    "            match(self.threshold,truths,defaults,self.variance,labels,loc_t,conf_t,idx)\n",
    "\n",
    "        # Send localization and confidence to GPU if available\n",
    "        if GPU:\n",
    "            loc_t = loc_t.cuda()\n",
    "            conf_t = conf_t.cuda()\n",
    "\n",
    "        # wrap targets as Variables (Include on graph, to use autograd)\n",
    "        loc_t = Variable(loc_t, requires_grad=False)\n",
    "        conf_t = Variable(conf_t,requires_grad=False)\n",
    "\n",
    "        pos = conf_t > 0\n",
    "        num_pos = pos.sum()\n",
    "\n",
    "        # Localization Loss (Smooth L1)\n",
    "        # Shape: [batch,num_priors,4]\n",
    "        pos_idx = pos.unsqueeze(pos.dim()).expand_as(loc_data)\n",
    "        loc_p = loc_data[pos_idx].view(-1,4)\n",
    "        loc_t = loc_t[pos_idx].view(-1,4)\n",
    "        loss_l = F.smooth_l1_loss(loc_p, loc_t, size_average=False)\n",
    "\n",
    "        # Compute max conf across batch for hard negative mining\n",
    "        batch_conf = conf_data.view(-1,self.num_classes)\n",
    "        loss_c = log_sum_exp(batch_conf) - batch_conf.gather(1, conf_t.view(-1,1))\n",
    "\n",
    "        # Hard Negative Mining\n",
    "        loss_c[pos] = 0 # filter out pos boxes for now\n",
    "        loss_c = loss_c.view(num, -1)\n",
    "        _,loss_idx = loss_c.sort(1, descending=True)\n",
    "        _,idx_rank = loss_idx.sort(1)\n",
    "        num_pos = pos.long().sum(1)\n",
    "        num_neg = torch.clamp(self.negpos_ratio*num_pos, max=pos.size(1)-1)\n",
    "        neg = idx_rank < num_neg.expand_as(idx_rank)\n",
    "\n",
    "        # Confidence Loss Including Positive and Negative Examples\n",
    "        pos_idx = pos.unsqueeze(2).expand_as(conf_data)\n",
    "        neg_idx = neg.unsqueeze(2).expand_as(conf_data)\n",
    "        conf_p = conf_data[(pos_idx+neg_idx).gt(0)].view(-1,self.num_classes)\n",
    "        targets_weighted = conf_t[(pos+neg).gt(0)]\n",
    "        loss_c = F.cross_entropy(conf_p, targets_weighted, size_average=False)\n",
    "\n",
    "        # Sum of losses: L(x,c,l,g) = (Lconf(x, c) + αLloc(x,l,g)) / N\n",
    "\n",
    "        N = num_pos.data.sum()\n",
    "        loss_l/=N\n",
    "        loss_c/=N\n",
    "        return loss_l,loss_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow there are the same loss implemented on Tensorflow (Notice that the code is a bit more complicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ssd_losses(logits, localisations,\n",
    "               gclasses, glocalisations, gscores,\n",
    "               match_threshold=0.5,\n",
    "               negative_ratio=3.,\n",
    "               alpha=1.,\n",
    "               label_smoothing=0.,\n",
    "               device='/cpu:0',\n",
    "               scope=None):\n",
    "    with tf.name_scope(scope, 'ssd_losses'):\n",
    "        lshape = tfe.get_shape(logits[0], 5)\n",
    "        num_classes = lshape[-1]\n",
    "        batch_size = lshape[0]\n",
    "\n",
    "        # Flatten out all vectors!\n",
    "        flogits = []\n",
    "        fgclasses = []\n",
    "        fgscores = []\n",
    "        flocalisations = []\n",
    "        fglocalisations = []\n",
    "        for i in range(len(logits)):\n",
    "            flogits.append(tf.reshape(logits[i], [-1, num_classes]))\n",
    "            fgclasses.append(tf.reshape(gclasses[i], [-1]))\n",
    "            fgscores.append(tf.reshape(gscores[i], [-1]))\n",
    "            flocalisations.append(tf.reshape(localisations[i], [-1, 4]))\n",
    "            fglocalisations.append(tf.reshape(glocalisations[i], [-1, 4]))\n",
    "        # And concat the crap!\n",
    "        logits = tf.concat(flogits, axis=0)\n",
    "        gclasses = tf.concat(fgclasses, axis=0)\n",
    "        gscores = tf.concat(fgscores, axis=0)\n",
    "        localisations = tf.concat(flocalisations, axis=0)\n",
    "        glocalisations = tf.concat(fglocalisations, axis=0)\n",
    "        dtype = logits.dtype\n",
    "\n",
    "        # Compute positive matching mask...\n",
    "        pmask = gscores > match_threshold\n",
    "        fpmask = tf.cast(pmask, dtype)\n",
    "        n_positives = tf.reduce_sum(fpmask)\n",
    "\n",
    "        # Hard negative mining...\n",
    "        no_classes = tf.cast(pmask, tf.int32)\n",
    "        predictions = slim.softmax(logits)\n",
    "        nmask = tf.logical_and(tf.logical_not(pmask),\n",
    "                               gscores > -0.5)\n",
    "        fnmask = tf.cast(nmask, dtype)\n",
    "        nvalues = tf.where(nmask,\n",
    "                           predictions[:, 0],\n",
    "                           1. - fnmask)\n",
    "        nvalues_flat = tf.reshape(nvalues, [-1])\n",
    "        # Number of negative entries to select.\n",
    "        max_neg_entries = tf.cast(tf.reduce_sum(fnmask), tf.int32)\n",
    "        n_neg = tf.cast(negative_ratio * n_positives, tf.int32) + batch_size\n",
    "        n_neg = tf.minimum(n_neg, max_neg_entries)\n",
    "\n",
    "        val, idxes = tf.nn.top_k(-nvalues_flat, k=n_neg)\n",
    "        max_hard_pred = -val[-1]\n",
    "        # Final negative mask.\n",
    "        nmask = tf.logical_and(nmask, nvalues < max_hard_pred)\n",
    "        fnmask = tf.cast(nmask, dtype)\n",
    "\n",
    "        # Add cross-entropy loss.\n",
    "        with tf.name_scope('cross_entropy_pos'):\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                                  labels=gclasses)\n",
    "            loss = tf.div(tf.reduce_sum(loss * fpmask), batch_size, name='value')\n",
    "            tf.losses.add_loss(loss)\n",
    "\n",
    "        with tf.name_scope('cross_entropy_neg'):\n",
    "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                                  labels=no_classes)\n",
    "            loss = tf.div(tf.reduce_sum(loss * fnmask), batch_size, name='value')\n",
    "            tf.losses.add_loss(loss)\n",
    "\n",
    "        # Add localization loss: smooth L1, L2, ...\n",
    "        with tf.name_scope('localization'):\n",
    "            # Weights Tensor: positive mask + random negative.\n",
    "            weights = tf.expand_dims(alpha * fpmask, axis=-1)\n",
    "            loss = custom_layers.abs_smooth(localisations - glocalisations)\n",
    "            loss = tf.div(tf.reduce_sum(loss * weights), batch_size, name='value')\n",
    "            tf.losses.add_loss(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
